# [054] Peripheral and Central Auditory Processing 2

# Overview of Central Auditory Pathways

![Screenshot 2021-12-14 at 08.46.31.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-14_at_08.46.31.png)

---

# Cochlea to Cochlear Nucleus

- ANFs = Spiral Ganglion Cells as they have their cell bodies in Spiral Ganglia
- Frequency preference of an IHC is determined by where it sits on the BM (as each frequency moves a different part of the Basilar Membrane)
- This means that Tonotopic representation of sound is maintained across the BM, Hair Cells and ANFs (Meaning that adjacent/distal cells respond to similar/different frequencies in a regular pattern).
- This means that as the IHCs are what generate Auditory Nerve Fibre APs, the frequency preference of an ANF is inherited from the Hair Cells that synapse onto it
- Each Type I ANF fibres contact only one IHC, but each IHC is innervated/synapses with 10-20 Type I ANFs (divergence).
- Many OHCs are innervated by 1 Type II ANF (convergence).

![Screenshot 2021-12-10 at 18.47.56.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_18.47.56.png)

---

# Auditory Nerve Fibres

- 30,000 ANFs: divided into type I and II fibres.
- ANFs are bipolar cells. Their cell bodies reside within spiral ganglion.
- They transmit information from cochlea to CNS.

**Type I ANFs**

- 95% of all ANFs are Type I Fibres.
- Each Type I ANF synapses with 1 IHC but each IHC synapses with multiple Type I ANFs (Divergence)

**Type II ANFs**

- 5% of all ANFs are Type II Fibres
- Each Type II ANF Synapses with 10-20 OHCs (Convergence)
- ANFs leave cochlea in Auditory Nerve component of CN VIII
    
    ![Screenshot 2021-12-10 at 18.48.48.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_18.48.48.png)
    

---

# Encoding a Wide Range of Sound Levels

- Typical sound levels range from 10-140 dB
- An increase in sound levels by 10 dB increases the power/intensity of the sound by x10
- In order to accurately/sensitively encode these wide ranges of sounds so that different dBs can be distinguished from one another, there are different ANFs that are sensitive to different dB values

![Screenshot 2021-12-14 at 08.58.38.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-14_at_08.58.38.png)

- ANFs vary in:
1. Spontaneous/Resting Firing Rate (Initial Plateau)
2. dB Activation Threshold (When ANFs first begin to increase their firing rate)
3. Saturation Point (Maximum Firing Rate/Final Plateau - Where increasing dB does not increase firing rate)
4. Coding Range (Width of the Firing Curve AKA between the Saturation Point and Threshold)
- When plotting Firing Rate against Input Intensity (dB), ANFs show a Sigmoidal Curve
- When the Spontaneous Firing Rate of the ANF Fibre increases, the Saturation Point also increases and hence, the Low and High SFR ANFs have their coding ranges positioned to help distinguish between Quiet and Loud Sounds

![Screenshot 2021-12-14 at 09.13.18.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-14_at_09.13.18.png)

---

# Cochlear Nucleus and Its Projections

### Cochlear Nucleus

- ANFs (Stimulated by IHCs in the Cochlea) project to the Cochlear Nucleus
- This is divided into Dorsal and ventral cochlear nuclei.
- 1st site of convergence/divergence of input.
- 1st inhibitory synapse

![Screenshot 2021-12-10 at 18.46.31.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_18.46.31.png)

### Tonotopic Projections from the Cochlea to the Cochlear Nucleus

- Orange: high frequency.
- Black: mid-frequency.
- Green/blue: low frequency.
- There is an organised Map of frequency along the cochlear nucleus, so that ANFs from the Cochlear Base/Apex project to the Anterior and Posterior regions of the Cochlear Nucleus.
- This Tonotopic projection of the Cochlear Nucleus is preserved to auditory cortex

![Screenshot 2021-12-10 at 18.52.43.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_18.52.43.png)

![Tonotopic-maps-of-the-basilar-membrane-and-cochlear-nucleus.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Tonotopic-maps-of-the-basilar-membrane-and-cochlear-nucleus.png)

### Neurons of the Cochlear Nucleus

- DCN: complex cell types whose response properties underpin analysis of complex sounds.
- VCN: simple response types, specialised for maintaining temporal sensitivity .
- VCN is further sub-divided into AVCN (anterior) and PVCN (posterior).
- Each sub-division is tonotopically organised and contains different types of neurons, defined anatomically or physiologically (Looking at Firing Rate over time → Initial High Firing Rate at Onset which decreases over time or Only respond at Onset)

![Screenshot 2021-12-10 at 18.53.32.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_18.53.32.png)

---

# Superior Olivary Complex

- From cochlear to nucleus, neurones project to superior olivary complexes bilaterally.
- This means that as both Cochlear Nuclei project to both Superior Olivary Complexes, there is convergence of input from 2 ears initially/for the first time at this level.
- This means it is Important for binaural hearing (hearing one sound from both ears).
- This is where Cochlear Efferent Neurons arise that project to the Cochlear to modulate its activity

![Screenshot 2021-12-10 at 18.46.31.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_18.46.31.png)

---

# Binaural Sound Localisation, Interaural Timing Differences (ITDs) and Interaural Level Differences (ILDs)

### Binaural Sound Localisation

- Relies upon comparing signals from both ears

![Screenshot 2021-12-14 at 10.07.48.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-14_at_10.07.48.png)

### Interaural Timing Differences (ITDs)

- If the sound is placed on one side of the head, the sound waves will reach the closer ear and hence, trigger ANF AP Generation here sooner than in the Further Away ear, producing an Interaural Timing Differences (Differences in when the Peak of the Sound Wave occurs)
- Used to localise low frequency sounds (<1.5k Hz as comparing the peaks of waveforms is required for determining ITD and at high frequencies, a lack of Phase Locking means ANF Firing Rate does not correspond well with frequency, so it becomes harder to determine ITD via differences in ANF Firing Rate.
- Head-size dependent: larger heads create larger range of ITDs as the sound wave must propagate a greater distance through the head to reach the ear that is further away from the sound, producing a greater time delay, allowing sounds to be more easily located.

![Screenshot 2021-12-14 at 10.24.12.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-14_at_10.24.12.png)

- Neural mechanisms allow for extremely accurate/fine temporal sensitivity and discrimination (can distinguish sounds as being separate with an ITD of 10-20 μS)
- Neuros in the Medial Superior Olive are sensitive to ITDs but the mechanisms that enable this sensitivity are poorly understood
- There is excitatory and input to the Medial Superior Olive from the Anteroventral Cochlear Nuclei bilaterally.

![Screenshot 2021-12-10 at 18.56.18.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_18.56.18.png)

### Interaural Level Differences (ILDs)

- If sound is placed on one side of the head, it will be perceived to be louder in the ear closer to the sound and quieter in the ear further away from the sound, producing an Interaural Level Difference
- Used to localise high frequency sounds.
- Frequency dependent as ILD (Difference in Waveform Amplitudes between wave reaching Right and Left Ear) larger at higher frequency.
- This is because at low frequencies, sound waves can defract and bend around the head, meaning that there is little dampening/attenuation of the Sound Waves as they project from the Right to the Left Ear, meaning there is a minor ILD here.
- High Frequency sounds cannot defract to bend around the head and hence, are significantly attenuated by the Sound passing through the Head, producing a pronounced ILD
- Head-size dependent: larger heads create bigger ILDs for same frequency as they attenuate the sound waves passing through it more significantly, meaning they are better at sound localisation.

![Screenshot 2021-12-14 at 10.14.13.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-14_at_10.14.13.png)

- Neurons in lateral part of superior olivary complex are sensitive to ILDs.
- Auditory Nerve sends excitatory projections to the Anteroventral Cochlear Nucleus, which sends excitatory projections to the Lateral Superior Olive
- This region of the Lateral Superior Olive also receives Inhibitory Input from the Contralateral Ear
- This means that when the sound is louder in the Ipsilateral Ear and quieter in the Contralateral Ear, there is increased excitatory drive and reduced inhibitory drive to the Lateral Superior Olive, causing Firing Rate of Neurons from the LSO to increase
- This means that when the sound is louder in the Contralateral Ear and quieter in the Ipsilateral Ear, there is increased inhibitory drive and reduced excitatory drive to the Lateral Superior Olive, causing Firing Rate of Neurons from the LSO to decrease
- This means that the firing rate of neuron from the LSO reflects whether the sound is louder in and therefore, closer to the Ipsilateral or Contralateral Ear

![Screenshot 2021-12-10 at 18.57.34.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_18.57.34.png)

---

# Inferior Colliculus

- Superior olivary complex projects to inferior colliculus.
- This is a site of convergence of Ascending Pathways from the Cochlear Nucleus via the Superior Olive and Lateral Lemniscus
- It is also a site of Divergence of Ascending Pathways from the Inferior Colliculus to the Superior Colliculus and the Medial Geniculate Body of the Thalamus and then to A1
- Site of convergence from ascending (Superior Olive and Lateral Lemniscus) and descending pathways.
- Obligatory station in ascending pathway so all Ascending Auditory Pathways must pass through the Inferior Colliculus.
- There is a tonotopic map of frequency in inferior colliculus, showing a Dorsolateral to ventromedial gradient from low to high frequency.

![Screenshot 2021-12-10 at 18.58.21.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_18.58.21.png)

---

# Superior Colliculus

- This contains a Map of Auditory Space and is subdivided into Rostral, Caudal, Medial and Lateral Aspects when viewed posteriorly
- Lateral and Medial Aspects of the Superior Colliculus receive Neurons conveying information about sounds located above and below the head/ears respectively
- Rostral and Caudal Aspects of the Superior Colliculus receive neurons conveying information about sounds located anterior and posterior to the head

![Screenshot 2021-12-10 at 18.58.47.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_18.58.47.png)

---

# Auditory Thalamus - Medial Geniculate Body

- Inferior colliculus projects to auditory thalamus (medial geniculate body (MGB)).
- MGB is divided into:
1. Ventral MGB: relaying frequency, intensity and binaural information to cortex. Similarly organised to IC (basic processing).
2. Medial MGB: detection of relative intensity and duration of sound. Some cross-model interactions. (may be involved in attention to sound)
3. Dorsal MGB: complex, possibly multi-modal/multi-sensory responses. (may be involved in auditory learning)

---

# Auditory Cortex

- Thalamus projects to auditory cortex.
- The Cortex helps to solve difficult perceptual problems involving auditory information such as:
1. Sound Localisation
2. Listening with Loud Background Noise
3. Learning
4. Language
- The Auditory Cortex contains multiple distinct cortical fields, each of which may be specialised for a different function in the interpretation of various aspects of auditory information

![Screenshot 2021-12-14 at 10.38.58.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-14_at_10.38.58.png)

- There are multiple tonotopic and non tonotopic Cortical Fields.
- This means that Auditory space map does not exist within auditory cortex, only in the Superior Colliculus.
- Neurones are broadly tuned to sound location and typically respond to contralateral auditory space.
- However, A1 is critical for Sound Localisation with reversible inactivation or permanent lesion of primary auditory cortex impairing sound localisation in both horizontal and vertical space.

![Screenshot 2021-12-14 at 10.38.14.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-14_at_10.38.14.png)

- There may be a division of function between areas of the Auditory Cortex for localising and identifying sounds, with there being 2 distinct pathways from the Auditory Pathway that mirror those of the visual system:
1. Where/Dorsal Pathway - Involved in Sound Localisation
2. What/Ventral Pathway - Involved in Identifying Sounds
- Evidence is less compelling in auditory cortex compared to visual cortex

---

# Processing Streams within the Auditory Cortex and Cortical Language Areas

### Cortical Language Areas

- Location and interconnections of posterior language area can create very specific deficits.
- Wernicke's Aphasia → Connection between Hearing Sounds and comprehending their meaning is severed, meaning the Px can still produce fluent speech but this is often non-meaningful

![Screenshot 2021-12-10 at 19.05.04.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_19.05.04.png)

---

# Speech and Language Processing and Maintaining Dynamic Range

### Speech and Language Processing

- Different parts of cortex need to work together and with lower brain centres in order to solve complex auditory problems

![Screenshot 2021-12-10 at 19.06.14.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_19.06.14.png)

---

# Auditory Scene Analysis and Descending Connections

### Descending Connections

- Descending connections exist from auditory cortex to thalamus (cortico-thalamic pathway) and inferior colliculus (corticocollicular pathway).
- Descending connections play a role in learning and plasticity (e.g. adapting to altered sound localisation cues due to unilateral hearing loss etc, allowing one to recover the ability to localise sounds).

![Screenshot 2021-12-14 at 10.51.56.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-14_at_10.51.56.png)

- Descending efferent connections exist from brainstem to cochlea via the Superior Olive (olivocochlear efferent system).
- This is divided into medial and lateral systems and was the first descending sensory system to be discovered

**Lateral Olivocochlear Fibres (LOC)**

- These originate from small neurons in and around lateral superior olive
- LOC fibres terminate on dendrites of ANFs underneath IHCs.
- LOC efferents can change firing of auditory nerve fibres.

**Medial Olivocochlear Fibres (MOC)**

- Originate from relatively large neurones around medial superior olive.
- MOC fibres terminate directly on bodies of OHCs.
- MOC efferents end on OHCs and can modify gain of OHCs to control gain of cochlear amplifier and hence adjust overall sensitivity to sound

![Screenshot 2021-12-14 at 10.57.48.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-14_at_10.57.48.png)

### Effect of Cochlear-Efferent Stimulation

- Olivocochlear Stimulation causes a right shift of the curve, meaning it becomes better at distinguishing between loud sound levels but worse at distinguishing between quiet sound levels (changing the dynamic/coding range of ANFs)

![Screenshot 2021-12-14 at 11.00.22.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-14_at_11.00.22.png)

---

# ANF Responses

![Screenshot 2021-12-10 at 19.08.36.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_19.08.36.png)

### Timing (Phase Locking)

- When a low frequency pure tone is fed into cochlea, auditory nerve fibres which are sensitive to these frequencies (low frequency) will fire as a function of time whereas ANFs sensitive to other frequencies will not.
- There is firing and non-firing of ANFs during peaks and troughs of wave respectively (known as Phase Locking as the ANF only fires/is locked to a particular phase of the Stimulus AKA a peak or trough).
- When a high frequency sound is fed, nerve fibres will fire randomly but at a high rate (no Phase Locking where firing corresponds with Stimulus Peaks) because ion channels cannot open and close quick enough to stay in synchrony with peaks and troughs of wave.
- Instead, a steady depolarisation is noted.
- If we modulate the sound by ↑ and ↓ amplitude gradually over time, firing of neurons is phase locked to increase their firing rate during high amplitude regions of the high frequency sound (Phase Locked to the Changing of the Wave Amplitude vs Peaks and Troughs of the Wave)
- When you move from ANFs that are selective to Low and High Frequency curves, the Frequency Tuning curve is shifted down and to the right so that the Characteristic Frequency is increased and Minimum Threshold is Decreased

![Screenshot 2021-12-10 at 19.12.28.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_19.12.28.png)

---

# Phase Locking and Volley Theory

### Mechanism of Phase Locking

- Peak in sound: deflection of Stereocilia towards the Kineocilium, depolarisating the Hair Cell then generating an action potential in the ANF.
- Troughs: deflection of hairs to opposite side away from the Kineocilium, hyperpolarising the Hair Cell so no action potential is generated in the ANF.
- As different ANFs respond to different peaks (with different intensities), this means that phase locking is not perfect in each ANF, so each peak on wavelength does not generate an action potential.
- However, as a population, ANFs can keep track of timing even though a single ANF fails to respond to every peak due to ANFs responding to different peaks → Volley Theory.
- ANF firing rates are altered by changes in frequency and intensity and hence, if the Firing rate of a single ANF increases, it is difficult to tell if this is due to increasing the stimulus/sound intensity or adjusting its frequency so that it is nearer to the optimum frequency of the ANF.
- By keeping track of frequency (where Peaks of ANF Firing correspond to Peaks of Sound waves, allowing you to determine peaks/sec) in a way that is independent of intensity via ANF Population Phase Locking, phase-locking helps to distinguish between frequency and intensity which hence allows for changes in firing rate to be identified as due to changes in sound frequency or intensity

![Screenshot 2021-12-10 at 19.11.20.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_19.11.20.png)

![Screenshot 2021-12-10 at 19.12.01.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_19.12.01.png)

---

# Frequency Tuning Curves

- Optimum Sound Frequency for a ANF (when Firing Rate is highest) can be determined by presenting sounds at different frequencies and sound levels/intensities and identifying the frequency of the lowest intensity sound that stimulates an ANF response and hence, what frequency the hair cell is most sensitive to
- This is represented in a Frequency Tuning Curve of log amplitude (dB) against log frequency for the frequency and amplitudes corresponding to ANF Firing
- When considering the Lowest Trough on this curve, the frequency at which it is found is known as the Characteristic Frequency and its amplitude/intensity is known as the Normal Threshold
- Depending on the Gradient of the Curve either side of the Minimum Point of the Curve, this can indicate whether there is a narrow or broad frequency tuning for this ANF
- Noise or drug damage reduced the sensitivity  of the ANF (elevates threshold/raises Minimum Point) and frequency selectivity (↑ bandwidth shallow gradient of the curve either side of the minimum point so that the ANF is not tuned to be selective to a narrow frequency).
- This does not alter the Characteristic Frequency though
- Frequency tuning shows that neurons prefer a frequency (can detect sound of a particular frequency at extremely low volumes).
- Because the width of curve is tight (bandwidth), it means a neuron responds to particular frequencies of sound.
- A wide/abnormal bandwidth means more neurons respond to a particular frequency of sound (makes it difficult to discriminate between different sound
frequencies).
    
    ![Screenshot 2021-12-10 at 19.13.33.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_19.13.33.png)
    

---

# Cochlear Implantation

- Peripheral auditory system converts vibration of air into electrical activity.
- Cochlear implants can do this artificially by detecting sounds using microphones and converting this into electrical signals that directly stimulate ANFs and passes electrical currents into CN VIII

![Screenshot 2021-12-10 at 19.14.34.png](%5B054%5D%20Peripheral%20and%20Central%20Auditory%20Processing%202%202ad8b34ad7ab45cfb59cf1a114308380/Screenshot_2021-12-10_at_19.14.34.png)

---

# Main Points

- Parallel processing occurs in central auditory system.
- Sound localisation cues are extracted by dedicated centres in midbrain.
- Tonotopic organisation is maintained up to (and beyond) primary auditory cortex.
- There may be a division of function between sound localisation and identification in auditory cortex.
- A specialised processing network exists for speech comprehension and production.
- Descending connections modulate auditory processing.

---